knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
install.packages("caret")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
install.packages("randomForest")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
install.packages("glmnet")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
dataset_structure <- str(data)
dataset_summary <- summary(data)
dataset_head <- head(data)
# Print the structure, summary, and first few rows of the dataset
cat("### Dataset Structure\n")
cat("```\n")
print(dataset_structure)
cat("```\n")
cat("### Dataset Summary\n")
cat("```\n")
print(dataset_summary)
cat("```\n")
cat("### First Few Rows of the Dataset\n")
cat("```\n")
print(dataset_head)
cat("```\n")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
# Convert categorical variables to factors
data$employmentStatus <- as.factor(data$employmentStatus)
data$isCurrentJob <- as.factor(data$isCurrentJob)
data$jobTitle.text <- as.factor(data$jobTitle.text)
data$location.name <- as.factor(data$location.name)
# Check for missing values
colSums(is.na(data))
# Impute missing values if any (Example: using median for numerical and mode for categorical)
data <- preProcess(data, method = 'medianImpute')
# Normalize numerical features
preproc <- preProcess(data, method = c('center', 'scale'))
# Load necessary libraries
library(readr)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_csv("Data.xls")
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
# Convert categorical variables to factors
data$employmentStatus <- as.factor(data$employmentStatus)
data$isCurrentJob <- as.factor(data$isCurrentJob)
data$jobTitle.text <- as.factor(data$jobTitle.text)
data$location.name <- as.factor(data$location.name)
# Check for missing values
missing_values <- colSums(is.na(data))
cat("### Missing Values\n")
cat("```\n")
print(missing_values)
cat("```\n")
# Impute missing values using median for numerical and mode for categorical variables
preproc <- preProcess(data, method = 'medianImpute')
data_imputed <- predict(preproc, data)
# Convert categorical variables to factors
data$employmentStatus <- as.factor(data$employmentStatus)
data$isCurrentJob <- as.factor(data$isCurrentJob)
data$jobTitle.text <- as.factor(data$jobTitle.text)
data$location.name <- as.factor(data$location.name)
# Check for missing values
missing_values <- colSums(is.na(data))
cat("### Missing Values\n")
cat("```\n")
print(missing_values)
cat("```\n")
# Impute missing values using median for numerical and mode for categorical variables
preproc <- preProcess(data, method = 'medianImpute')
data_imputed <- predict(preproc, data)
# Convert categorical variables to factors
data <- data %>%
mutate(across(where(is.character), as.factor))
# Check for missing values
missing_values <- colSums(is.na(data))
missing_values
# Impute missing values with median for numeric variables and mode for categorical variables
data <- data %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(where(is.factor), ~ ifelse(is.na(.), as.factor(names(sort(table(.), decreasing = TRUE))[1]), .)))
# Convert categorical variables to factors
data <- data %>%
mutate(across(where(is.character), as.factor))
# Check for missing values
missing_values <- colSums(is.na(data))
print(missing_values)
# Impute missing values
data <- data %>%
mutate(
ratingCeo = ifelse(is.na(ratingCeo), median(ratingCeo, na.rm = TRUE), ratingCeo),
ratingBusinessOutlook = ifelse(is.na(ratingBusinessOutlook), median(ratingBusinessOutlook, na.rm = TRUE), ratingBusinessOutlook),
ratingRecommendToFriend = ifelse(is.na(ratingRecommendToFriend), median(ratingRecommendToFriend, na.rm = TRUE), ratingRecommendToFriend),
isCurrentJob = ifelse(is.na(isCurrentJob), as.factor(names(sort(table(isCurrentJob), decreasing = TRUE))[1]), isCurrentJob),
employmentStatus = ifelse(is.na(employmentStatus), as.factor(names(sort(table(employmentStatus), decreasing = TRUE))[1]), employmentStatus),
jobEndingYear = ifelse(is.na(jobEndingYear), median(jobEndingYear, na.rm = TRUE), jobEndingYear),
jobTitle.text = ifelse(is.na(jobTitle.text), as.factor(names(sort(table(jobTitle.text), decreasing = TRUE))[1]), jobTitle.text),
location.name = ifelse(is.na(location.name), as.factor(names(sort(table(location.name), decreasing = TRUE))[1]), location.name)
)
# Create new features if necessary
data <- data %>%
mutate(ratingWorkLifeBalance_bin = ifelse(ratingWorkLifeBalance >= 3, "Good", "Bad"),
ratingCultureAndValues_bin = ifelse(ratingCultureAndValues >= 3, "Good", "Bad"))
# Convert new features to factors
data <- data %>%
mutate(across(ends_with("_bin"), as.factor))
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(data$ratingOverall, p = .8,
list = FALSE,
times = 1)
dataTrain <- data[ trainIndex,]
dataTest  <- data[-trainIndex,]
# Train a random forest model
rf_model <- randomForest(ratingOverall ~ ., data = dataTrain, importance = TRUE)
print(rf_model)
# Predict on test data
rf_predictions <- predict(rf_model, dataTest)
# Evaluate model performance
rf_confusion <- confusionMatrix(rf_predictions, dataTest$ratingOverall)
# Convert ratingOverall to a factor
dataTrain$ratingOverall <- as.factor(dataTrain$ratingOverall)
dataTest$ratingOverall <- as.factor(dataTest$ratingOverall)
# Train a random forest model
rf_model <- randomForest(ratingOverall ~ ., data = dataTrain, importance = TRUE)
print(rf_model)
# Predict on test data
rf_predictions <- predict(rf_model, dataTest)
# Ensure predictions are treated as factors
rf_predictions <- as.factor(rf_predictions)
# Evaluate model performance
rf_confusion <- confusionMatrix(rf_predictions, dataTest$ratingOverall)
print(rf_confusion)
# Train a support vector machine model
svm_model <- svm(ratingOverall ~ ., data = dataTrain)
print(svm_model)
# Predict on test data
svm_predictions <- predict(svm_model, dataTest)
# Evaluate model performance
svm_confusion <- confusionMatrix(svm_predictions, dataTest$ratingOverall)
print(svm_confusion)
# Define the parameter grid
rf_grid <- expand.grid(mtry = c(2, 4, 6, 8))
# Train with cross-validation
rf_tuned <- train(ratingOverall ~ ., data = dataTrain, method = "rf",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rf_grid)
print(rf_tuned)
# Evaluate tuned model on test data
tuned_rf_predictions <- predict(rf_tuned, dataTest)
tuned_rf_confusion <- confusionMatrix(tuned_rf_predictions, dataTest$ratingOverall)
print(tuned_rf_confusion)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
knitr::opts_chunk$set(echo = TRUE)
# Load necessary libraries
library(readxl)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(e1071)
library(glmnet)
# Load the dataset
data <- read_excel("Data.xls")
# Explore the dataset
str(data)
summary(data)
head(data)
# Convert categorical variables to factors
data <- data %>%
mutate(across(where(is.character), as.factor))
# Ensure all categorical variables are factors
data <- data %>%
mutate(across(where(is.character), as.factor))
# Remove duplicate rows
data <- data %>% distinct()
# Check for missing values
missing_values <- colSums(is.na(data))
missing_values
# Impute missing values with median for numeric variables and mode for categorical variables
data <- data %>%
mutate(across(where(is.numeric), ~ ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%
mutate(across(where(is.factor), ~ ifelse(is.na(.), as.factor(names(sort(table(.), decreasing = TRUE))[1]), .)))
# Convert categorical variables to factors
data <- data %>%
mutate(across(where(is.character), as.factor))
# Check for missing values
missing_values <- colSums(is.na(data))
print(missing_values)
# Impute missing values
data <- data %>%
mutate(
ratingCeo = ifelse(is.na(ratingCeo), median(ratingCeo, na.rm = TRUE), ratingCeo),
ratingBusinessOutlook = ifelse(is.na(ratingBusinessOutlook), median(ratingBusinessOutlook, na.rm = TRUE), ratingBusinessOutlook),
ratingRecommendToFriend = ifelse(is.na(ratingRecommendToFriend), median(ratingRecommendToFriend, na.rm = TRUE), ratingRecommendToFriend),
isCurrentJob = ifelse(is.na(isCurrentJob), as.factor(names(sort(table(isCurrentJob), decreasing = TRUE))[1]), isCurrentJob),
employmentStatus = ifelse(is.na(employmentStatus), as.factor(names(sort(table(employmentStatus), decreasing = TRUE))[1]), employmentStatus),
jobEndingYear = ifelse(is.na(jobEndingYear), median(jobEndingYear, na.rm = TRUE), jobEndingYear),
jobTitle.text = ifelse(is.na(jobTitle.text), as.factor(names(sort(table(jobTitle.text), decreasing = TRUE))[1]), jobTitle.text),
location.name = ifelse(is.na(location.name), as.factor(names(sort(table(location.name), decreasing = TRUE))[1]), location.name)
)
# Create new features if necessary
data <- data %>%
mutate(ratingWorkLifeBalance_bin = ifelse(ratingWorkLifeBalance >= 3, "Good", "Bad"),
ratingCultureAndValues_bin = ifelse(ratingCultureAndValues >= 3, "Good", "Bad"))
# Convert new features to factors
data <- data %>%
mutate(across(ends_with("_bin"), as.factor))
set.seed(123)  # For reproducibility
trainIndex <- createDataPartition(data$ratingOverall, p = .8,
list = FALSE,
times = 1)
dataTrain <- data[ trainIndex,]
dataTest  <- data[-trainIndex,]
# Convert ratingOverall to a factor
dataTrain$ratingOverall <- as.factor(dataTrain$ratingOverall)
dataTest$ratingOverall <- as.factor(dataTest$ratingOverall)
# Train a random forest model
rf_model <- randomForest(ratingOverall ~ ., data = dataTrain, importance = TRUE)
print(rf_model)
# Predict on test data
rf_predictions <- predict(rf_model, dataTest)
# Ensure predictions are treated as factors
rf_predictions <- as.factor(rf_predictions)
# Evaluate model performance
rf_confusion <- confusionMatrix(rf_predictions, dataTest$ratingOverall)
print(rf_confusion)
# Train a support vector machine model
svm_model <- svm(ratingOverall ~ ., data = dataTrain)
print(svm_model)
# Predict on test data
svm_predictions <- predict(svm_model, dataTest)
# Evaluate model performance
svm_confusion <- confusionMatrix(svm_predictions, dataTest$ratingOverall)
print(svm_confusion)
library(gbm)
library(caret)
# Remove duplicate rows
data <- data %>% distinct()
# Ensure all categorical variables are factors
data <- data %>%
mutate(across(where(is.character), as.factor))
# Convert ratingOverall to a factor
dataTrain$ratingOverall <- as.factor(dataTrain$ratingOverall)
dataTest$ratingOverall <- as.factor(dataTest$ratingOverall)
# Train a GBM model
gbm_model <- gbm(ratingOverall ~ ., data = dataTrain, distribution = "multinomial", n.trees = 100, interaction.depth = 3, shrinkage = 0.01, cv.folds = 5)
summary(gbm_model)
# Predict on test data
gbm_predictions <- predict(gbm_model, dataTest, n.trees = gbm_model$n.trees, type = "response")
gbm_predictions <- apply(gbm_predictions, 1, which.max)
gbm_predictions <- factor(gbm_predictions, levels = levels(dataTrain$ratingOverall))
# Evaluate model performance
gbm_confusion <- confusionMatrix(gbm_predictions, dataTest$ratingOverall)
print(gbm_confusion)
# Define the parameter grid
rf_grid <- expand.grid(mtry = c(2, 4, 6, 8))
# Train with cross-validation
rf_tuned <- train(ratingOverall ~ ., data = dataTrain, method = "rf",
trControl = trainControl(method = "cv", number = 5),
tuneGrid = rf_grid)
print(rf_tuned)
# Evaluate tuned model on test data
tuned_rf_predictions <- predict(rf_tuned, dataTest)
tuned_rf_confusion <- confusionMatrix(tuned_rf_predictions, dataTest$ratingOverall)
print(tuned_rf_confusion)
# Calculate accuracy for Random Forest
rf_accuracy <- rf_confusion$overall['Accuracy']
# Calculate accuracy for SVM
svm_accuracy <- svm_confusion$overall['Accuracy']
# Calculate accuracy for GBM
gbm_accuracy <- gbm_confusion$overall['Accuracy']
# Create a data frame with accuracy values
accuracy_values <- data.frame(
Model = c("Random Forest", "SVM", "GBM"),
Accuracy = c(rf_accuracy, svm_accuracy, gbm_accuracy)
)
# Plot the accuracies
library(ggplot2)
ggplot(data = accuracy_values, aes(x = Model, y = Accuracy, fill = Model)) +
geom_bar(stat = "identity") +
ylim(0, 1) +
xlab("Model") +
ylab("Accuracy") +
ggtitle("Comparison of Model Accuracies") +
theme_minimal() +
theme(legend.position = "none")
